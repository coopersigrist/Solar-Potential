import pandas as pd
import csv
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from os.path import exists
import json
import pgeocode
import geopandas as gpd
from shapely.geometry import Point
from geopandas import GeoDataFrame
import plotly.graph_objects as go
from decimal import Decimal


# This code is used to combine the Json of solar installation sizes into a total sq footage
def combine_counts(solar_size_json):
    counts = []
    for zip in solar_size_json:
        count = 0
        if type(zip) == str:
            lzip = json.loads(zip)
            for elem in lzip:
                count += elem[0] * elem[1]
        counts.append(count)

    return counts

# Loads Solar data for given zipcodes, also cleans and calculates new values
def load_solar_dat(zip_codes, load_dir="/Clean_Data/census_zip_usable.csv"):

    # If we have already cleaned data then we load that instead of processing
    if load_dir is not None and exists(load_dir):
        return pd.read_csv(load_dir)

    zip_codes = list(map(int, zip_codes))
    # df = pd.read_csv('solar_zip_usable.csv')
    df = pd.read_csv('../Proj_sunroof_scraping/Data/solar_by_zip.csv')
    df = df[df["region_name"].isin(zip_codes)]
    df = df.drop_duplicates(subset=['region_name'], keep='first')
    df = df[['region_name','yearly_sunlight_kwh_kw_threshold_avg','number_of_panels_total','install_size_kw_buckets_json','existing_installs_count','percent_covered','carbon_offset_metric_tons']]
    solar_size_json = df['install_size_kw_buckets_json']

    # Potential solar panels are saved as a json of different sizes, we use combine counts to get a single square-footage number of potential solar panel area
    counts = combine_counts(solar_size_json.values)
    df['square_footage'] = counts

    # We have to scale by "percent covered" as that is the percent of the zipcode area that has data, but census dat attempts to cover 100% of population
    df['number_of_panels_total'] *= (100/ df['percent_covered']) 
    df['square_footage'] *= (100/ df['percent_covered']) 
    df['carbon_offset_metric_tons'] *= (100/ df['percent_covered']) 
    df['existing_installs_count'] *= (100/ df['percent_covered']) 

    # This metric for solar potential is somewhat arbitrary, it is simply the avg amount of solar energy produced if all possibe solar panels were built
    df['solar_potential'] = df['square_footage'] * df['yearly_sunlight_kwh_kw_threshold_avg']
    
    df.to_csv("solar_zip_usable.csv", index=False)

    return df


# Loads Cenus data for given zipcodes, also cleans and calculates new values
def load_census_dat(zip_codes, load_dir="/Clean_Data/solar_zip_usable.csv"):

    # If we have already cleaned data then we load that instead of processing
    if load_dir is not None and exists(load_dir):
        return pd.read_csv(load_dir)

    zip_codes = list(map(int, zip_codes))
    df = pd.read_csv('../Proj_sunroof_scraping/Data/census_by_zip.csv')
    df = df[df["zcta"].isin(zip_codes)]

    # Removes bad data, should be already removed from the zip.csv, but this to be certain.
    mask = df['Median_income'] <= 0
    df = df[~mask]

    # Also removes duplicates (which happen for some reason even when there are no duplicates in zips)
    df = df.drop_duplicates(subset=['zcta'], keep='first')
    df = df.sort_values('zcta')
    df.to_csv("census_zip_usable.csv", index=False)

    return df

def fit_dat_and_plot(x, y, deg, label=""):

    # fits an arbitrary degree polynomial and then plots it

    if deg == "linear":
        deg = 1
    if deg == "quadratic":
        deg = 2

    coeff = np.polynomial.polynomial.Polynomial.fit(x, y, deg).coef
    pred = np.zeros(y.shape)
    poly_str = '%.1E' % Decimal(coeff[0])
    for i in range(deg + 1):
        pred += coeff[i] * (x ** i)
        if i > 0:
            poly_str = '%.1E' % Decimal(coeff[i]) +"x^" +str(i) +" + "  + poly_str

    plt.plot(x, pred, label=str(deg) + " degree polynomial best fit -- " + label, linewidth=3)  

    return coeff

# Creates a scatter plot as you'd expect with autogenerated title
def scatter_plot(x, y, xlabel="", ylabel="", title=None, fit=None, label="", show=True, color="palegreen"):

    dat = pd.DataFrame()
    dat['x'] = x
    dat['y'] = y
    dat = dat.dropna(axis=0)

    if fit is not None:
        dat = dat.sort_values("x")
        dat["x"] /= max(dat["x"])
        if type(fit) is int:
            fit = [fit]
        for deg in fit:
                fit_dat_and_plot(dat["x"].values, dat["y"].values, deg, label)

    plt.scatter(dat['x'], dat['y'], color=color, alpha=0.1, label=label)

    if show:
        plt.xlabel(xlabel)
        plt.ylabel(ylabel)
        plt.legend()
        if title is None:
            plt.title(ylabel + " versus " + xlabel)
        else:
            plt.title(title)
        plt.show()

def complex_scatter(census_df, solar_df, x, y, xlabel, ylabel, title=None, bins=None):
    '''
    Inputs:
        Cenus_df : DataFrame object of all saved census data
        Solar_df : DataFrame object of all saved Proj Sunroof data
        x : The x axis for the plot (will be a col of either census or solar)
        y : Ditto but for the y axis
        bins: A list of tuples with (key:str, range:tuple, label:str, color:str)
            - key wil denote which col we are binning on, range will determine the range that we will mask the data for
            - label will be a label for plottin, color will be the color for the scatter plot
    '''
    cenus_keys = census_df.keys()
    solar_keys = solar_df.keys()
    for (key, range, label, color) in bins:
        print(key)
        low, high = range
        if key in cenus_keys:
            mask = (low <= census_df[key]) # & (census_df[key] < high)
            scatter_plot(x=x[mask], y=y[mask], fit=[1], show=False, label=label, color=color)
        elif key in solar_keys:
            mask = (low <= solar_df[key]) and  (solar_df[key] < high)
            scatter_plot(x=x[mask], y=y[mask], fit=[1], show=False, label=label, color=color)
        else:
            print("Key error in Complex Scatter on key:", key, " -- not a valid key for census or solar, skipping")
        
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.legend()
    if title is None:
        plt.title(ylabel + " versus " + xlabel)
    else:
        plt.title(title)
    plt.show()




# Creates a US map plot of the dat, edf should be provided, but if it isn't then it will be created as necessary using the zipcodes provided
def geo_plot(dat, color_scale, title, edf=None, zipcodes=None):

    # This should basically never get called since we define edf below, but if you were to import this you'd have to make sure zipcodes are provided to create the edf
    if edf is None:
        if zipcodes is None:
            print("invalid Geo Plotting, you must include an EDF or zipcode list")
            return -1
        else:
            nomi = pgeocode.Nominatim('us')
            edf = pd.DataFrame()
            edf['Latitude'] = (nomi.query_postal_code(zipcodes).latitude)
            edf['Longitude'] = (nomi.query_postal_code(zipcodes).longitude)
            edf['zip_code'] = zipcodes

    # For scaling of the bar, we do 15 ticks over the range of the data
    dat_range = max(dat) - min(dat)
    edf['dat'] = dat
    clean_dat = edf.dropna(axis=0)

    fig = go.Figure(data=go.Scattergeo(
            lon = clean_dat['Longitude'],
            lat = clean_dat['Latitude'],
            mode = 'markers',
            marker = dict(
            color = clean_dat['dat'],
            colorscale = color_scale,
            reversescale = True,
            opacity = 0.6,
            size = 10,
            colorbar = dict(
                titleside = "right",
                outlinecolor = "rgba(68, 68, 68, 0)",
                ticks = "outside",
                showticksuffix = "last",
                dtick = dat_range/15
            )
            )))

    fig.update_layout(
            title = title,
            geo_scope='usa',
        )
    fig.show()

def get_clean_zips():
    if exists("zips_usable.csv"):
        zips = pd.read_csv('zips_usable.csv',dtype=str) 
        zips = zips.drop_duplicates(subset=['zcta'], keep='first')
        return zips['zcta'].values
    else:
        zips = pd.read_csv('../Proj_sunroof_scraping/Data/zips.csv',dtype=str) 
        zips = zips.drop_duplicates(subset=['zcta'], keep='first')
        zip_codes = zips['zcta'].values
        solar_df = load_solar_dat(zip_codes)
        census_df = load_census_dat(zip_codes)

        # Remove all zips not in solar data
        z_temp = zips[zips['zcta'].isin( solar_df['region_name'].astype(str).str.zfill(5))]
        # Remove all zips not in census data (including median income outliers)
        z_temp2 = z_temp[z_temp['zcta'].isin(census_df['zcta'].astype(str).str.zfill(5))]

        # Save this new zip list
        z_temp2.to_csv("zips_usable.csv", index=False)

        return z_temp2['zcta'].values

# Loads both the census and solar data across all zips and returns both dfs, it is necessary to have already created the solar_by_zip and census_by_zip data under the Data folder though
def load_data():
    print("Loading Data")
    # Loads Zip Codes from Data Folder
    # zips = pd.read_csv('../Proj_sunroof_scraping/Data/zips.csv',dtype=str) 
    # zips = zips.drop_duplicates(subset=['zcta'], keep='first')
    # zip_codes = zips['zcta'].values

    zip_codes = get_clean_zips() 

    print("number of zip codes:", len(zip_codes))
    solar_df = load_solar_dat(zip_codes)
    print("number of zip codes with solar data:", len(solar_df))
    census_df = load_census_dat(zip_codes)
    print("number of zip codes with census data:", len(census_df))

    solar_df['solar_potential_per_capita'] = solar_df['solar_potential'] / census_df['Total_Population']
    solar_df = solar_df.sort_values('region_name')
    solar_df.to_csv("solar_zip_usable.csv", index=False)

    nomi = pgeocode.Nominatim('us')

    edf = pd.DataFrame()
    edf['Latitude'] = (nomi.query_postal_code(zip_codes).latitude)
    edf['Longitude'] = (nomi.query_postal_code(zip_codes).longitude)
    edf['zip_code'] = zip_codes

    return zip_codes, solar_df, census_df, edf






